{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4a1d141",
   "metadata": {},
   "source": [
    "<h3>라이브러리</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35ffca49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mj120\\OneDrive\\Desktop\\3학년 2학기\\SW캡스톤디자인\\데이터\\paneldata(피앰아이)\\Quickpoll\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "#쿠레 설치 및 import\n",
    "#! pip install -U sentence-transformers faiss-cpu\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9243039a",
   "metadata": {},
   "source": [
    "<h3>함수</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3adc2629",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2차원에서 비교\n",
    "def embeding(emb_list,user_emb):\n",
    "    #문항 벡터 평균\n",
    "    #(N,D)  /dim=0(평균 축) << 임베딩의 동일 차원(feature) ,=1 <<정보손실\n",
    "    rep_emb = torch.stack(emb_list, dim=0).mean(dim=0)\n",
    "    #만약을 위하여\n",
    "    if rep_emb.dim() == 1:\n",
    "        rep_emb = rep_emb.unsqueeze(0)\n",
    "\n",
    "    # 평균 후 정규화 / 코사인 값 -1~1 보장 /\n",
    "    # dim=1 각 행마다 정규화(파이토치) 유클리드거리 p=2, dim=1 =벡터의 길이를 1로 변환\n",
    "    rep_emb = F.normalize(rep_emb, p=2, dim=1, eps=1e-12)\n",
    "\n",
    "    # 사용자 질의 차원 정리 (D,) → (1, D)\n",
    "    if user_emb.dim() == 1:  \n",
    "        user_emb = user_emb.unsqueeze(0)\n",
    "\n",
    "    # dim=1 각 행마다 정규화(파이토치) 유클리드거리 p=2, dim=1 =벡터의 길이를 1로 변환\n",
    "    user_emb = F.normalize(user_emb, p=2, dim=1, eps=1e-12)\n",
    "\n",
    "    # dim=1 행\n",
    "    scores = F.cosine_similarity(rep_emb, user_emb, dim=1)\n",
    "    scores = scores.clamp(-1, 1)  # 안정성 확보\n",
    "\n",
    "    k = min(5, scores.numel())\n",
    "    topk = torch.topk(scores, k=k, largest=True)\n",
    "\n",
    "    return topk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e5ac09",
   "metadata": {},
   "source": [
    "<h3>데이터 로드</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ee07f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mj120\\AppData\\Local\\Temp\\ipykernel_21472\\1533138882.py:1: DtypeWarning: Columns (3,10,11,14,15,16,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  person_outer=pd.read_csv(\"full_outer_loyalty.csv\")\n"
     ]
    }
   ],
   "source": [
    "person_outer=pd.read_csv(\"full_outer_loyalty.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cdac7b",
   "metadata": {},
   "source": [
    "<h3>데이터 업데이트</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b83af5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #title1\n",
    "# title={\n",
    "#     문장의 문맥을 살리는 결합 방식\n",
    "#     모든 불용어가 제거된 질문 문항 + 선지 \n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b556992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #title2\n",
    "# title={\n",
    "#     문항과 선지의 관계를 살리는 결합 방식\n",
    "#     모든 불용어가 제거된 질문 문항 + [SEP] + 선지\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7870af11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #title3\n",
    "# title={\n",
    "#     문항과 선지의 관계를 살리는 결합 방식\n",
    "#     최소한의 불용어가 제거된 질문 문항 + [SEP] + 선지\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16111e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #title4\n",
    "# title={\n",
    "#     문항과 선지의 관계를 살리는 결합 방식\n",
    "#     온전한 질문 문항 + [SEP] + 선지\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a59cb069",
   "metadata": {},
   "outputs": [],
   "source": [
    "for qnum, qtext in title.items():\n",
    "    if qnum in person_outer.columns:\n",
    "        person_outer[qnum] = person_outer[qnum].apply(\n",
    "            lambda v: f\"{qtext}{v}\" if pd.notna(v) else v\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e9f8442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for qnum, qtext in title.items():\n",
    "#     if qnum in person_outer.columns:\n",
    "#         person_outer[qnum] = person_outer[qnum].apply(\n",
    "#             lambda v: f\"{qtext}[SEP]{v}\" if pd.notna(v) else v\n",
    "#         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca93205",
   "metadata": {},
   "source": [
    "<h3>모델 호출</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e3fa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"nlpai-lab/KURE-v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85186c55",
   "metadata": {},
   "source": [
    "<h3>샘플 추출</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1ac8d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=person_outer.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22f36688",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1 = sample[['문항21', '문항26_1', '문항26_2', '문항29']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b137867a",
   "metadata": {},
   "source": [
    "<h3>#mental health</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc9e71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "qp21_emb = model.encode(\n",
    "    sample1['문항21'],\n",
    "    batch_size=64,\n",
    "    convert_to_tensor=True,     \n",
    "    normalize_embeddings=True \n",
    ")\n",
    "qp26_1_emb = model.encode(\n",
    "    sample1['문항26_1'],\n",
    "    batch_size=64,\n",
    "    convert_to_tensor=True,     \n",
    "    normalize_embeddings=True \n",
    ")\n",
    "qp26_2_emb = model.encode(\n",
    "    sample1['문항26_2'],\n",
    "    batch_size=64,\n",
    "    convert_to_tensor=True,     \n",
    "    normalize_embeddings=True \n",
    ")\n",
    "qp29_emb = model.encode(\n",
    "    sample1['문항29'],\n",
    "    batch_size=64,\n",
    "    convert_to_tensor=True,     \n",
    "    normalize_embeddings=True \n",
    ")\n",
    "user_emb = model.encode(\n",
    "    \"돈으로 스트레스를 많이 느끼는 사람\",\n",
    "    batch_size=64,\n",
    "    convert_to_tensor=True,     \n",
    "    normalize_embeddings=True \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2de885",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_list = [qp21_emb,qp26_1_emb,qp26_2_emb,qp29_emb]\n",
    "\n",
    "topk = embeding(emb_list,user_emb)\n",
    "\n",
    "top_idx = topk.indices.detach().cpu().numpy()\n",
    "top_scores = topk.values.detach().cpu().numpy()\n",
    "\n",
    "result = sample1.iloc[top_idx].copy()\n",
    "result[\"similarity\"] = top_scores\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b4ca98",
   "metadata": {},
   "source": [
    "<h3>#Offline & Travel</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45753c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample2 = sample[[\"문항1\",\"문항9\",\"문항23\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40a86ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "qp1_emb = model.encode(\n",
    "    sample2['문항1'],\n",
    "    batch_size=64,\n",
    "    convert_to_tensor=True,     \n",
    "    normalize_embeddings=True \n",
    ")\n",
    "qp9_emb = model.encode(\n",
    "    sample2['문항9'],\n",
    "    batch_size=64,\n",
    "    convert_to_tensor=True,     \n",
    "    normalize_embeddings=True \n",
    ")\n",
    "qp23_emb = model.encode(\n",
    "    sample2['문항23'],\n",
    "    batch_size=64,\n",
    "    convert_to_tensor=True,     \n",
    "    normalize_embeddings=True \n",
    ")\n",
    "user_emb = model.encode(\n",
    "    \"여행을 좋아하는 사람\",\n",
    "    batch_size=64,\n",
    "    convert_to_tensor=True,     \n",
    "    normalize_embeddings=True \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f1a5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_list = [qp1_emb,qp9_emb,qp23_emb]\n",
    "\n",
    "topk = embeding(emb_list,user_emb)\n",
    "\n",
    "top_idx = topk.indices.detach().cpu().numpy()\n",
    "top_scores = topk.values.detach().cpu().numpy()\n",
    "\n",
    "result = sample2.iloc[top_idx].copy()\n",
    "result[\"similarity\"] = top_scores\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47123d68",
   "metadata": {},
   "source": [
    "<h3>비유사 카테고리 결과</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674ce6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_list = [qp21_emb,qp26_1_emb,qp26_2_emb,qp29_emb]\n",
    "\n",
    "topk = embeding(emb_list,user_emb)\n",
    "\n",
    "top_idx = topk.indices.detach().cpu().numpy()\n",
    "top_scores = topk.values.detach().cpu().numpy()\n",
    "\n",
    "result = sample1.iloc[top_idx].copy()\n",
    "result[\"similarity\"] = top_scores\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
